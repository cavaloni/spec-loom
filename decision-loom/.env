DATABASE_URL="file:./dev.db"

OPENROUTER_API_KEY="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"
OPENROUTER_BASE_URL="https://openrouter.ai/api/v1"
OPENROUTER_MODEL_SUGGEST="google/gemini-3-flash-preview"
OPENROUTER_MODEL_SUMMARY="anthropic/claude-haiku-4.5"
OPENROUTER_MODEL_GENERATE="openai/gpt-5.2"
OPENROUTER_MODEL_REFLECT="google/gemini-3-pro-preview"

# Rate limiting disabled for local development
# UPSTASH_REDIS_REST_URL=
# UPSTASH_REDIS_REST_TOKEN=

# =============================================================================
# OBSERVABILITY / TELEMETRY
# =============================================================================

# Structured logging level (debug, info, warn, error)
LOG_LEVEL=debug

# OpenTelemetry - Traces export to Grafana Tempo, Jaeger, or any OTLP endpoint
# Leave empty to disable tracing
# OTEL_EXPORTER_OTLP_ENDPOINT=http://localhost:4318
# OTEL_SERVICE_NAME=decision-loom

# Langfuse - LLM observability (prompt/response tracking, token usage, costs)
# Sign up at https://cloud.langfuse.com or self-host
# LANGFUSE_PUBLIC_KEY=pk-lf-...
# LANGFUSE_SECRET_KEY=sk-lf-...
# LANGFUSE_BASE_URL=https://cloud.langfuse.com

# LLM client settings
OPENROUTER_TIMEOUT_MS=120000
OPENROUTER_MAX_RETRIES=0
